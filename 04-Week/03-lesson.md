# 4.3 Lesson Plan: Usability Testing

---

## Overview

Today's class will dive deeper into the design process's testing phase by focusing on the fundamentals of usability testing. Students will create usability testing plans, conduct usability tests, measure the success rate of their tests, and share their results with others.

## Learning Objectives

By the end of class today, students will be able to:

1. Write a usability testing plan.

2. Conduct a usability test.

3. Analyze usability testing data.

## Class at a Glance

The main difference between today's class and the previous lecture on guerrilla user testing focuses on metrics. We really want to impress upon students the importance of "measuring" success and defining what those metrics look like.

Here's what the day looks like at a high level:

1. Developing usability testing plans
2. Conducting usability tests
3. Analyzing usability tests

By the end of today's class, students should grasp the usability testing process.

### Time Tracker 

| | Topic | Time |
| -- | -- | -- |
|  | [Office Hours](#Section1) | 45 Mins |
| 1. | [Welcome and Share Objectives](#1-instructor-do-welcome-and-share-objectives-2-min) | 2 Mins |
| 2. | [Usability Testing](#2-instructor-do-usability-testing-15-min) | 15 Mins |
| 3. | [Usability Testing Plan Activity](#3-student-do-usability-testing-plan-activity-15-min) | 15 Mins |
| 4. | [Usability Testing Plan Activity Review](#4-instructor-do-usability-testing-plan-activity-review-10-min) | 10 Mins |
| 5. | [Iterate Your Usability Testing Plan Activity](#5-student-do-iterate-your-usability-testing-plan-activity-5-min) | 5 Mins |
| 6. | [Recruiting Participants and Conducting a Usability Test](#6-instructor-do-usability-testing-recruiting-participants-and-conducting-a-usability-test-8-min) | 8 Mins |
| 7. | [Analyzing and Reporting User Research](#7-instructor-do-analyzing-and-reporting-user-research-10-min) | 10 Mins |
| 8. | [Usability Testing Activity](#8-student-do-usability-testing-activity-55-min) | 55 Mins |
| 9.| [Break](#Break)| 15 Mins |
| 10.| [Usability Testing Activity Review](#10-instructor-do-usability-testing-activity-review-15-min) | 15 Mins |
| 11.| [Working Session ](#11-student-do-working-session-30-min) | 30 Mins |
| 12.| [Recap and End Class](#12-instructor-do-recap-and-end-class-3-min) | 3 Mins |
| | [Office Hours](#Section21) | 30 Mins |


- Empower your TA to help you stay on track. If you're like most instructors, you'll talk until the clock runs out.

- Use an online timer, which you or your TA can set at the start. You can add a timer to your Chrome browser, found here: [Chrome Timer](https://chrome.google.com/webstore/detail/timer/hepmlgghomccjinhcnkkikjpgkjibglj?hl=en).

## Instructor Notes

Many of our activities were written for in-person classes, so we've added in-line callouts (usually indicated by this icon: > :globe_with_meridians:) to let you know how to adapt an activity for online delivery.

Remember, you can lose the class’s focus in the time it takes to open a new tab. Practice your transitions to and from the slideshow.

> :globe_with_meridians: **Online Recommendation:** Narrating what you're doing during transitions eases students’ feelings of uncertainty and fills awkward silences. Here are some examples of what you can say during common transitions:
- From sharing the slideshow to Zoom gallery view: “I’m going to stop sharing my screen for a moment while we review this activity.”
- From sharing the slideshow to sharing a tab on your browser: “Bear with me as I switch over to my browser for the next demonstration.”

Transitions and activities tend to take longer in virtual classrooms. If you find that you are running short on time, feel free to combine Activity and Review sections by doing the activity as a class instead of creating breakout groups. 

## Preparing for Class

**Preparation tips:** 
    - Be sure to read through the entire lesson plan, slides, student activity files, as well as the Time Tracker.  
    - Make notes so that you are thoroughly prepared to teach and support students.
    - As you lecture, relate your own on-the-job experience whenever possible to bring what students are learning to life and connect it to their future careers. Look for the :gem: **Designer insight** icon throughout this lesson plan, which offers an opportunity to share an anecdote from your professional experience.

**Review your lecture slides:**
    - [04-Week/01-Slides/04.3 Usability Testing Slides](https://docs.google.com/presentation/d/10ZK_VjiZTM7OQ2b9n4q0kL5ectPKdci1-_NUnX-i_WM/edit?usp=sharing)

**The UX/UI boot camp is hard:**
    - Students might struggle with usability testing and analysis. Be sure to workshop with students and check in on their progress.

- **Summarize the activity instructions out loud:**
  - Students will readily dive into the activities if you provide verbal guidance. There's no need to read the instructions word for word, but do summarize the key steps.

- **Using Zoom:**
  -  It takes time to become proficient using Zoom, the primary online instructional tool. Please refer to the following guide for help performing essential online teaching tasks (sharing screens, polling, managing breakout rooms, etc.):
  - [Zoom Reference Guide](https://docs.google.com/document/d/19MtogY4tO4aMPgQ0mlHpdtvi8rmkt9efN__mBngs9tg/edit)

  - If needed, review [Strategies for Class Online](https://github.com/coding-boot-camp/ux-ui-curriculum-version2/tree/master/01-lesson-plans/04-Week#strategies-for-class-online).  

## Class Materials

- If you need additional guidance when preparing for activities or want to see what the activity outcomes look like, please see the instructor-facing activity solution files:

  - [04-Week/05-Instructor Resources/02-Instructor-Activity-Solutions/](https://drive.google.com/drive/u/2/folders/1O3rSolEHndX9LRDs-8d2IyHto2vXNMAo)

Coordinate with the Cohort Student Support Manager (SSM), as they will help provide some classroom materials.

## Class Video

Watch a sample video of this class being taught by Kyle Overton at George Washington University.

- [Class Video](https://codingbootcamp.hosted.panopto.com/Panopto/Pages/Viewer.aspx?id=8b00e68d-44d2-41f5-8b30-ab6200f6d2a8)


## Office Hours (45 min before class)

Encourage students to come early and use the time provided and not to be afraid to ask questions.

> Do your part by engaging students who come early and participate in office hours.

---

## 1. Instructor Do: Welcome and Share Objectives (2 min)

Open and download today’s slides. TAs should share them with the students via Slack: [04-Week/01-Slides/04.3 Usability Testing Slides](https://docs.google.com/presentation/d/10ZK_VjiZTM7OQ2b9n4q0kL5ectPKdci1-_NUnX-i_WM/edit?usp=sharing).

**Welcome to class!** 

> :globe_with_meridians: **Online Recommendation:** Start today's class with a quick engagement tactic to get everyone focused on the boot camp content.  

- Today we will be diving deep into user testing. That means we're in the testing phase of the design thinking process. 
- ***Connect today's lesson to the real world of design work.*** In the real world, designers take time to iterate and test their prototypes to make sure their designs are ready for the market. This is a critical skill and an asset to design teams because the design process is iterative and being able to validate and test your ideas with users is essential to solving your users' needs.

-  ***Engage the class.*** 
  - Help sharpen everyone's focus and get their minds ready for a day of user testing by asking students to draw from their own experience:
    - Question 1: When have you installed something—or introduced a new system or device—and then watched others struggle to use it? 
      - If students struggle, suggest a TV remote, car stereo, or even a pet who doesn't understand a new toy or feeder you've given them.
    - Question 2: Share a time someone gave you something and you couldn't figure out how to use it. 


> :globe_with_meridians: **Online Recommendation:** Have students engage by raising their hands to speak or addressing the question via Slack.

- Finally, walk through today's learning objectives. 

Now, get ready to dive into usability testing and planning.

## 2. Instructor Do: Usability Testing (15 min)

> :pushpin: **Important Point:** The goal of this section is to explain what usability tests aim to achieve, show what a testing plan looks like, and prepare students to write their own usability testing plans. This lecture supports today's first learning objective, which is for students to write a testing plan.

Today we'll explore the testing phase of the design thinking process. The testing phase is where designers learn more about the user and find reasons to refine their prototype. 

- While conducting tests, designers pay close attention to their prototype, the context, and the scenario in which they're testing. Additionally, designers observe how the user interacts with the prototype and collect feedback. By paying close attention, they can see where there are gaps and issues with their design.

- Testing can be done during any stage of the design thinking process, but it is most often executed along with prototyping a design. Before a designer can run a test, however, they must write down their testing plan.

Collecting, sorting, and understanding data gathered during user research and usability testing is a critical UX skill.

> :gem: **Designer Insight:** Share a usability test *planning* skill that you've mastered over time.
>
> - Invite a TA to briefly share as well. 

> :briefcase: **Employer Competitive Note:** As a UX/UI designer, planning usability tests are relevant to the industry because you will be required to design and test your solutions. Bringing user testing skills to a team will make you more employable. 

### Review the Usability Testing Tool Snapshot.

**What:** Guerrilla user testing is a rapid, low-cost method to evaluate how effective an interface is.
What makes guerrilla user testing unique is that participants are not recruited in advance. Instead, members of the public are approached by those conducting the study in the REAL WORLD.

**When:** Getting quick baseline measures of an existing website, app, or mobile experience, including informal user research and insights about user expectations.

**Why:** The goal is to identify any usability problems, collect qualitative and quantitative data, and determine the participant’s satisfaction with the product.



## SLIDES 1-4
Review

## SLIDE 5
### What Is Usability Testing?

Usability testing evaluates a product by testing it on users. This is a way to see how easy something is to use by seeing how real users interact with it. The goal of usability testing is to satisfy users and identify any usability problems.

## SLIDE 6
### Why Do We Do Usability Testing? 

Usability testing lets the design and development teams identify problems before they are coded or released to users. The earlier in the process issues are identified and fixed, the less costly the fixes will be in dollars and staff time. Fixing issues early will help your team stay on schedule and improve your users' experience. During a usability test, you will:

1. Learn if participants are able to complete specified tasks successfully.

    - Identify how long it takes to complete specified tasks.

2. Find out how satisfied participants are with your website or other product.

    - Identify the changes required to improve user performance and satisfaction.

3. Analyze the performance to see if it meets your usability objectives.

    - Identify user pain points: since the user won't always tell you what they don't like, you have to find out by observing them.

4. Identify user bias.

    - We all possess bias. We want to know whether problems arise for the reasons we think they do or for other reasons that we can directly observe through research. Assumptions and user bias need to be researched and removed.

    - Learn where assumptions were wrong: we're making a hypothesis about our user. We're not going to be right 100% of the time. We want to know where we're wrong. 

## SLIDE 7
Review

## SLIDE 8
Testing Labs are not required to conduct an effective usability test. Any of these settings will work:
- Fixed laboratory having two or three connected rooms outfitted with audiovisual equipment  
- Room with portable recording equipment  
- Room with no recording equipment, as long as someone is observing the user and taking notes  
- Remotely, with the user in a different location

> **Instructor Note:** Check to see what students have learned so far about planning usability tests. 

> :globe_with_meridians: **Online Recommendation:** Address any questions that were posted to Slack.

## SLIDE 9
### Four Usability Testing Techniques

1. Moderated in-person testing:

   - Moderated tests are recommended during the design phase—when a team has a design that hasn’t yet been fully developed.

   - You can run a moderated test to find the potential issues of your working prototype.

   - A facilitator/moderator (UX tester) is co-located with the participant (user) and watched by the observer (UX designer). Often takes place in a lab.

2. Moderated remote testing:

   - The participant and facilitators are in different locations. Screen-sharing software allows the facilitator to watch the participant attempt tasks remotely.

3. Unmoderated remote testing:

   - This occurs remotely without a moderator.

   - It offers quick, robust, and inexpensive usability testing results.

   - This method typically employs usability testing tools that automatically gather participant feedback and record their behavior.

   - Have TAs slack out a link to [https://www.usertesting.com/](https://www.usertesting.com/).

4. Guerrilla user testing:

   - The term "guerrilla" refers to its "out in the wild" style and can be conducted anywhere. The researcher typically hands their testable prototype to anyone who fits their user persona.

   - Startups and student projects typically deploy guerrilla user testing tactics.

   - Guerrilla user testing has a reputation for being used only when a lack of money or organizational support prohibits doing "proper" user research.

> :gem: **Designer Insight:** choose one of the above techniques and share your experience using it.

## SLIDE 10
### The Usability Testing Process

There are five main steps in the usability testing process:
1. Planning user testing
2. Recruiting participants
3. Conducting the usability test
4. Analyzing the usability test
5. Reporting the usability test results


## SLIDE 11
Questions??

## SLIDE 12
Figma Prototype Demo

## SLIDE 13
Review

## SLIDE 14
**Planning User Testing**

- ***Craft a plan and write a moderator guide.***

   - Think about the tasks users carry out on your website that you would like to test. 

   - You may or may not execute the user tests, so consider how to communicate with other user testing teammates.

## SLIDE 15
- ***Define user goals.***

   - Think about the activities users carry out on your website that you would like to test. Put each one in words in a way that is specific and measurable.

   - A user goal is a final state for which the user strives. To get to the target, the user should perform some tasks (user tasks).

   - Describe the entire activity, telling users what you want to be done but not how to do it.

## SLIDE 16
- ***Create a scenario to test.***
- Scenarios describe the stories and context behind why a specific user or user group comes to your site.
  
- Scenarios describe what users want to do, not how they should do it.
  
- Scenarios note the goals and questions to be achieved and sometimes define the possibilities of how the user(s) can reach them on the site.


## SLIDE 17
- ***Define the tasks and steps for a scenario.***
- Define the tasks and steps.
  
   - Write down the steps you want the user to go through to complete a task.


## SLIDE 18
- ***Select a user testing method.***
   - Will it be a moderated remote, moderated in-person, or a mix of in-person and unmoderated studies?


## SLIDE 19
- ***Make sure the scenarios are specific and measurable.***
- A scenario should be created so that it’s easily understood, and we can tell when it’s completed.
  
- Include pre- and post-test questions.
  
 - Pre-test questions are an opportunity to ask questions before users know what the study is about.
   
- Post-test questions: In the end, we want to ask a few open-ended questions about what the users would improve, what comments they want to add, and what issues they had.


## SLIDE 20
Review slide


## SLIDE 21
Questions??

## SLIDE 22
Review

## SLIDES 23
### Disneyparks.com Case Study

> :globe_with_meridians: **Online Recommendation:** Share your screen if you'd like, and open the Disneyparks link. Alternatively, students can open the link on their screens.

Review the [Disneyparks.com](https://disneyparks.disney.go.com/) example of a usability test plan and its tasks.

- Open [Disneyparks.com](https://disneyparks.disney.go.com/) in your browser.


## SLIDE 24
Let’s brainstorm together. What goals or objectives might we have for a usability test of this website? Who are the target users?

## SLIDE 25
**A. Usability test plan goals and objectives.** 

Let's imagine Disney's objective is to: 

1. Understand how people navigate to and within the site. Some questions we might ask are:
   
   - How do users arrive at the site? 
   - How do they get started? 
   - Where do they begin their search for information?

2. Understand whether users can successfully locate information for planning their vacations. 


## SLIDE 26
**B. Usability test plan, Users.** 

Next, Disney would identify the target user:

1. Primary users: Vacation planners—people planning a Disney vacation for themselves or for a client.

2. Secondary users: Vacation attendees—people interested in learning about things they might do on vacation being planned for them. 

## SLIDE 27
**Disneyparks.com scenario:** Then, we would create a scenario:

**[https://disneyparks.disney.go.com/](https://disneyparks.disney.go.com/) scenario:** You and your spouse have three young kids between the ages of 7 and 12. You are taking them to Disney World for summer vacation. You're planning to go in June. You have a budget of $6,500 for lodging, meals, and park tickets. You'll use the Disney Parks website to book your trip.

## SLIDE 28
**Disneyparks.com tasks:** We would use the scenario to write specific tasks:

1. Show me how you would start planning your trip using Disney's website.

2. Your kids are young and they want to stay near the Magic Kingdom. Tell me which hotels are close to the Magic Kingdom.


## SLIDE 29
Questions??

## SLIDE 30
## 3. Student Do: Usability Testing Plan Activity (15 min)

**TAs,** slack out the following links: 

Usability Testing Plan Activity: [04-Week/02-Activities/04.3-01 Usability Testing Plan Google Doc](https://docs.google.com/document/d/1wHS9AC7yVjpnGOZl98ILKND8S3AnmytJ_LchlYw35-Q/edit?usp=sharing)

Usability Test Plan Template: [04-Week/02-Activities/04.3-01 Usability Testing Plan Template](https://docs.google.com/spreadsheets/d/1s0p7RfUEJvBSH2UBn4wA0STqk7VBKG1jCjqvTriW6WQ/edit?usp=sharing)

> :globe_with_meridians: **Online Recommendation:** Students will work independently here, so recommend that everyone "mute" themselves and use Gallery View on Zoom. 

### Summary

Before testing their prototypes from the last class, students first have to make a plan. This activity teaches them to think carefully about their testing goals while creating a short usability testing plan. 

They'll use their testing plans in the next activity.  

### Instructions

> **Instructor Note:** The activity has three parts. The review is Part 2 (section 4) and an iteration is Part 3 (section 5).

- Students will work independently. 
- Part 1: Students will set up and fill in their testing plan template (15 minutes).  
- They'll fill in all five sections: goals/output, assumptions, steps, success criteria, and notes.

### Instructor and TAs 

> :globe_with_meridians: **Online Recommendation:** Monitor students and offer support to anyone who gets stuck on the template. 


*Some people are paralyzed by forms*: if you see students getting stuck, suggest that they talk through why a plan is helpful. The plan template is one way to think about user testing.  

**Deliverable**

Students will write two tasks for participants to follow during usability testing and share their templates in Slack. 


## SLIDE 31
## 4. Instructor Do: Usability Testing Plan Activity Review (10 min)

> :globe_with_meridians: **Online Recommendation:** Bring everyone's attention back to your screen and lead a review of the first part of the testing plan activity.  

> **Instructor Note:** Remind students to post their plans to Slack.


**Start the review.**

Aim to review at least two students' testing plans.

- Scroll through Slack and choose a student's testing plan.
- Ask them to present their work to the class.
  - The student should walk through each section of his or her testing plan.

**Provide feedback.**

> :globe_with_meridians: **Online Recommendation:** Students can raise their hands to provide feedback as well as post it in Slack.

Ask the TAs to offer their critique and provide your own feedback. Feedback prompts:

- *Is the testing plan clear and concise overall?*
- *Is the testing goal/output clear?*
- *What works well?*
- *What do you think could be improved?*

Now, discuss any **common misconceptions and FAQ**s that new designers face when it comes to testing. For example:

- Testing is time consuming and hard to pull off. False. We are going to practice how user testing can and should be part of your process.
- User testing should only be done on final products. Super false. You are trying to learn something about your users; if you start early and test often, you can iterate your solutions faster.

Finally, provide students with a few pieces of **actionable feedback** that they can apply directly to their next testing plan. For example: 

- Is your testing goal too big? Test one feature, not an entire product suite at first. 
- Is your plan written in a way you can give it to a stranger and they could use it? Don't assume your plan audience has user testing knowledge.

Wrap up the critique and let students know that you'll give them five minutes to iterate their testing plans. 

## SLIDE 32
## 5. Student Do: Iterate Your Usability Testing Plan Activity (5 min) 

> **Instructor Note:** This is Part 3 of the activity that students started in Section 3.

### Instructions

- Based on the review session you just completed, students will spend five minutes iterating their usability testing plans. 

### Instructor and TAs

> :globe_with_meridians: **Online Recommendation:** Monitor students as they work and offer support if needed. Encourage them to keep refining their plans and simplifying the user task as they polish and iterate their plans. 

**Deliverable**

An iterated testing plan, which doesn't need to be shared. 

## SLIDE 33
Review

## SLIDE 34
### Recruiting Participants (Step 2)

One of the most important aspects of any user research study is recruiting great participants. Research is an investment; if all goes well, you’ll get out more than you put in. But like all investments, great results are not guaranteed. To get the most bang for your buck—and to avoid wasting time and resources—a well-defined target audience is a must.


## SLIDE 35
The process of recruiting people for research studies can be broken down into four areas:

1. Targeting by building a quality participant profile.
    - This means focusing on demographics, geography, psychographics, and behaviors.
2. Using screener surveys to recruit the right people.
3. Managing incentives so you can run successful research.
4. Sustaining research. It's harder than you think because recruiting isn't easy. You have problems like:
    - There’s a plethora of channels and methods you can use to find participants, but different channels will work better for different projects.
    - Repeatedly using the same channels and methods will result in diminishing returns (i.e., burning out participants).
    - It’s difficult to find eligible participants who meet the criteria for niche studies.
   - It’s a lengthy and complex process, but some projects don’t have the luxury of time.


## SLIDE 36
### Recruiting Research Tools

- Social media
- Craigslist 

**TAs,** slack out these links for students to read after class: 

- [Userinterviews.com](https://www.userinterviews.com/)
- [Usertesting.com](https://www.usertesting.com/)

> **Instructor Note:** Pause for any questions and remind students that they will need to get creative with recruiting users but they have an advantage in being a student. There are many in the UX community very willing to help but you have to put it out in public.


## SLIDE 37
Review

## SLIDE 38
### Usability Test: Conducting a Usability Test (Step 3)

Here you'll explain types of usability testing techniques, best practices for conducting usability tests, and how to categorize usability test results. This will prepare students to conduct their own usability tests.

:clapper: **Start by playing a two-minute usability testing video clip.**

A usability test involves preparation and analysis and is regarded as one of the most valuable of all UX research techniques. Usability tests can provide both *quantitative* and *qualitative* data to guide designers and product teams toward better solutions.

## SLIDE 39
### Moderator Preparation Responsibilities

1. Set up the environment.
2. Prepare the observers.
3. Care for and brief the participants.
4. Conduct the test.

## SLIDE 40
### Choose a Moderating Technique

- It’s your job as a moderator—the person leading usability sessions—to make sure the sessions go well. You need to provide the team with the information they need to improve their designs.

- You need to make participants feel comfortable, make sure they proceed through the tasks, and minimize or manage any technical difficulties and observer issues.

- As a moderator, you'll use one of four available techniques:

  - **Concurrent Think Aloud (CTA):** As testers interact with a product, they think aloud while they work.

  - **Concurrent Probing (CP):** The researcher asks probing questions during the usability test.

  - **Retrospective Think Aloud (RTA):** The moderator asks participants to retrace their steps when the session is complete.

  - **Retrospective Probing (RP):** The moderator asks participants questions about their thoughts and feelings after they use a product or prototype.

## SLIDE 41
### Conducting the Usability Test

When conducting the test, the test plan is your guide. 

***Tip:*** Conducting a pilot study—or test run—the day before the actual sessions start helps your performance as a moderator because you get to practice working through all the aspects of the test.


## SLIDE 42
Five guidelines for conducting the test:
1. Give test subjects one task at a time.

   - It’s your job to be quiet and listen; let the participants do the talking. That’s how you and your team will learn.
2. Try to make them feel at home.
3. Use a testing script.
4. Introduce the test clearly, letting testers know how long the testing will take.
5. Let participants set the pace.
6. Let participants struggle.

   - Get participants to elaborate on their thoughts: ask, “Why?” or say, “Tell me more about that."
7. Participants should indicate when a task is complete.
8. Remind them to think aloud.

### After You Conclude the Test

This is the time to conclude the interview with final thoughts and questions.

## SLIDE 43
### Disneyparks.com Example

- Review the Disneyparks.com example of a usability testing script.

## SLIDE 44
Questions??

## SLIDE 45
Review

## SLIDE 46
### Usability Test: Analyzing the Usability Test (Step 4)

Here, you're giving students a sense of what happens after testing. First, you'll introduce metrics and their usefulness. Then you'll walk through some common metrics. Finally, you'll walk through the Disneyparks case study. 

> :briefcase: **Employer Competitive Note:** As a UX/UI designer, analyzing usability tests and generating scores based on metrics is relevant to the industry because these artifacts will most likely be the proof of your user testing process. A usability test results in feedback from users and designers and hiring managers want to see how you use and generate this level of analysis.  


## SLIDE 47
### Quantifying User Research Is Part of the Job

As designers, we need to connect UX metrics to organizational or business goals or KPIs, such as increasing revenue or decreasing cost. 

Using numbers to quantify the impact of design helps us communicate with our teammates and other stakeholders that the user-centered design process delivers continuous improvement to products and the company's bottom line. Companies continue to invest in design because UX generates a high return on investment (ROI).

- For example: As part of the portfolio review during the hiring process, a candidate might be asked to talk about how he or she measured the success of designs or prototypes.

## SLIDE 48
"Measurement is the first step that leads to control and eventually to improvement. If you can’t measure something, you can’t understand it. If you can’t understand it, you can’t control it. If you can’t control it, you can’t improve it."
— Dr. H. James Harrington

   - Dr. H. James Harrington is an author and guru on improving business operations. 
  
   - **TAs,** slack out a link to the book *Business Process Improvement*: [https://www.amazon.com/Business-Process-Improvement-Breakthrough-Competitiveness/dp/0070267685/ref=sr_1_2?dchild=1&keywords=business+process+improvement+james+harrington&qid=1586464864&sr=8-2](https://www.amazon.com/Business-Process-Improvement-Breakthrough-Competitiveness/dp/0070267685/ref=sr_1_2?dchild=1&keywords=business+process+improvement+james+harrington&qid=1586464864&sr=8-2)


## SLIDE 49
### Common UX Metrics and Organizational KPIs

*Benchmarking the User Experience*, by Jeff Sauro cites two categories of metrics: 
   - Study-level metrics 
   - Task-level metrics 

Study-level metrics measure the overall experience:

   1. System Usability Scale (SUS): This 10-item questionnaire measures the perceived usability of any UX.

   2. Net Promoter Score (NPS): The Net Promoter Score is a popular/notorious measure of customer loyalty that can be applied to all interfaces and experiences. Customers rank the experience on a scale of 1 to 10.

Task-level metrics measure a specific task if the study has tasks:

   3. Success rate: Many define this measurement as the percentage of tasks that users complete correctly. This fundamental metric of effectiveness tells you whether participants can complete a task (1 = success and 0 = failure). You can calculate this by taking the total number of tasks completed successfully and dividing it by the total number of tasks.

**TAs**, slack out for students to read at home: [https://www.amazon.com/Benchmarking-User-Experience-Jeff-Sauro/dp/0692149090](https://www.amazon.com/Benchmarking-User-Experience-Jeff-Sauro/dp/0692149090)


## SLIDE 50
> **Say,** "How do you know your prototype works?"

As a UX designer, you can only find that out by user testing. But testing alone is not enough—we need to quantify the results to validate our designs. Success rate is about validating your ideas. 

- Success rate goes back to the definition of traditional usability and includes two primary components—user effectiveness and efficiency. 

- Success rates are great metrics because they are easy to collect and a very telling statistic. After all, if users can't accomplish their target task, all else is irrelevant. User success is the bottom line of usability. Simplified success rates are best used to provide a general picture of how your site supports users and how much improvement is needed to make the site really work.

## SLIDE 51
Some examples of tasks we might test could be:
- Search results success
- Time to upload a photo
- Number of users successfully creating a profile for a new account

### Three KPIs to Measure Success Rate

1. Success rate: The level to which users are able to complete tasks successfully using the product.

2. Time-on-task: The average amount of time it takes users to complete a given task from the moment they start until they are done. 

   - It seems straightforward, yet time measurements are complicated. Be sure you're aware and mitigating common traps such as users trying too hard, measuring time when users fail to complete tasks, normalizing time data, etc. 

3. Lostness: The lostness metric is a measure of efficiency using a digital product. It tells you how lost people are when they use the product. 

   - Lostness scores range from 0 to 1. A high score (closer to 1) means that people are very lost and having trouble finding what they need. A low score (closer to 0) means that people find what they want relatively easily. Lostness is calculated using the optimal and actual number of steps it takes a user to complete a task.

- **TAs,** slack out: [https://measuringu.com/tag/task-time/](https://measuringu.com/tag/task-time/).

- **TAs,** slack out: [https://artplusmarketing.com/the-complete-guide-to-measuring-lostness-c890cc71fe05](https://artplusmarketing.com/the-complete-guide-to-measuring-lostness-c890cc71fe05).


## SLIDE 52
### Disneyparks.com Case Study: How to Measure Success Rate

We want to measure task success, so let's look at an example of how to measure task success.

- The following table shows task success data from a study of five usability tests. In it, we tested Disneyparks.com, asking five users to perform five tasks.

- When a participant was successful completing a task, it was marked S.

- When a participant was NOT successful completing a task, it was marked F.

- For every S, we add 1 for a total of 8.

- There were 20 tasks total, so we divide 8/20 and get a success rate of 40%.

## SLIDE 53
### Even Google Does It

Google designed the HEART framework to help its UX designers focus on only a handful of key UX measurements. According to five user-centric categories, Google's HEART framework evaluates a product or feature idea: happiness, engagement, adoption, retention, and task success.


## SLIDE 54
### Usability Testing Analysis

Conducting usability tests is only half the journey to an ideal UX solution. We want to quantify our tests to share that data and use it to iterate upon our product effectively.

- Designers collect a lot of feedback when they are conducting usability tests. The challenge of collecting so much feedback is how to organize it in a way that allows a team to prioritize their next steps.

_REVIEW SLIDE_

## SLIDE 55
Review

## SLIDE 56
Review

## SLIDE 57
### Usability Test: Reporting the Usability Test Results (Step 5)

The last step of the testing process is to share your research with the design team. As designers, it's essential to understand how to present your research to teammates, stakeholders, executives, and clients.

- Research is used to make informed business decisions.

- Knowing your users' needs means you can design a product with value.


### Write a UX Brief to Share Research

It helps the entire project or product team to align on the deliverable(s) and any factors that might contribute to the satisfactory conclusion of work.

***So, what goes into a design brief?***

- Keep the raw research to yourself and focus on visualizing your findings.
- Prepare your research and communicate your findings.
- Plan the next steps by prioritizing the problems the product team should solve.

***Whom are design briefs written for?***

- Anyone who has to implement, understand, or reference your design to solve the problem.
- Typically, a project client.
- They are written as though the project client is new to the project as a way to improve the story.

To create a great UX, design and research need to happen in tandem.

## SLIDES 58-60
Review

## SLIDES 61-62
Let's look at a visualization of user tests conducted by Disneyparks.com. We can use simple iconography to visualize the task success rate.

### DisneyParks.com Before and After 

So what does that look like? When research is done well, you might see small iterative changes. For example, let's look at the following screenshots of Disneyparks.com from 2018 and 2020.

- 2018: There were two levels of navigation.
- 2020: They removed the top level of navigation. Perhaps this was because two navigations were confusing to users. However, you can tell that overall, not much has changed. Depending on their KPIs, they would be best served by running multivariate testing, but that's hard to discern as an outsider.

Say, "It's time to practice doing some usability testing on your own."

*Connect the earlier lesson to this one:* Designers are looking to see that their prototype embodies heuristic principles. As they run usability tests, heuristics are part of their evaluation criteria, in addition to all the insights they gain while observing their test users.


**TAs,** Slack out these links for students to review after class and keep as testing planning resources:

- [https://www.nngroup.com/articles/success-rate-the-simplest-usability-metric/](https://www.nngroup.com/articles/success-rate-the-simplest-usability-metric/)
- [https://ai.google/research/pubs/pub36299](https://ai.google/research/pubs/pub36299)
- [https://measuringu.com/completion-rates/](https://measuringu.com/completion-rates/)
- [https://www.usability.gov/how-to-and-tools/methods/system-usability-scale.html](https://www.usability.gov/how-to-and-tools/methods/system-usability-scale.html)
- [https://measuringu.com/nps-go/](https://measuringu.com/nps-go/)

Now it's time for students to get hands-on practice with these ideas and do their own usability testing with the following activity.


## SLIDE 63
Questions??

## SLIDE 64
## 8. Student Do: Usability Testing Activity (55 min)

**TAs,** slack out the link to the Usability Testing Plan Activity:

[04-Week/02-Activities/04.3-02 Usability Testing Google Doc](https://docs.google.com/document/d/1__rOddSFaDtZ_NTUK9dzGy8amjPDI512oMto_1QZHog/edit?usp=sharing).

> **Instructor note:** Give students an estimate for how long to spend on each test, then give announcements throughout to keep them on task.

### Summary

In this activity, students will work in groups of six to perform three to five usability tests on the interactive prototypes they created in InVision or Figma. 

### Instructions

> :globe_with_meridians: **Online Recommendation:** Create breakout rooms for groups of six. Assign a student to be the group's representative and choose the first tester. 

- Students will set up a Slack group for their team and then follow the activity document's instructions for the testing steps.

- Each group will perform a group-moderated user test.

###Instructor and TAs** 

> :globe_with_meridians: **Online Recommendation:** Drop into the breakout rooms and encourage students to begin testing, then move onto the next test, and the keep going. 

Watch out for students who are not sharing their prototypes and not using their testing plans and encourage them to focus on executing their plan. 

### Deliverable

Students will have conducted three to five usability tests and filled out the results tab on their Usability Testing Template. 

## SLIDE 65
## 9. Break (15 min)

## SLIDE 66
## 10. Instructor Do: Usability Testing Activity Review (15 min)

> :globe_with_meridians: **Online Recommendation:** Bring everyone's attention back to your screen to lead a review of the usability testing activity. 

> **Instructor Note:** *First things first:* Congratulate the students on having conducted their first user tests! 
>
> Testing can be a very humbling experience, so take a moment to acknowledge students' hard work.

**Engage students in discussion.**

> :globe_with_meridians: **Online Recommendation:** Students can raise their hands to provide feedback as well as post it in Slack.

Prompt students to discuss their work by asking some of the following questions:

- *How did your usability testing go?*
- *What surprised you?*
- *What did you learn?*
- *What went well?*
- *What didn't go well?*
- *What would you do differently?*

Now, discuss any **common misconceptions and FAQs** that new designers face when it comes to usability testing. For example:

- Usability tests are better in person. False. We can gather as much data through remote testing. 

- Usability tests don't need to be tested on the actual device. False. If you are testing the usability of an iPhone app, test on the iPhone, not on a simulation of an iPhone on your computer.

Finally, provide students with a few pieces of **actionable feedback** that they can apply directly to their usability tests in the next class. For example: 

- Use screen recording technology to capture the whole experience. You will miss nuances in the user test on the day and having a recording will allow you to go back and catch your users' full experience with the prototype.
- If your user tester didn't know where to start, iterate your script and test the prototype again.

> **Instructor Note:** See if anyone has questions about the testing process. 

## 11. Student Do: Working Session (30 min)

> :pushpin: **Important Point:** The goal of this section is to give students in-class time to get started on their challenge and provide feedback to one another. 

>
> - You have flexibility on how to use this time. Some suggestions: encourage more user testing, analyzing their testing results, and iterating their prototypes.

> :globe_with_meridians: **Online Recommendation:** Put up a timer in the corner of your screen to help students keep track of time. Give them a five-minute warning before the full 30 minutes are up. 

**TAs,** slack out for students to experiment with during work session: 

- [Usability Testing challenge Template](https://docs.google.com/spreadsheets/d/1hIHEkzY7CDUtNmtCeRqar6Y6USCeDfYuslcEtt0srq4/edit?usp=sharing)

- [Usability Testing Tool Maze](https://maze.design/)

Maze is a user testing platform that turns your prototype into actionable insights from real users. Some students might wish to use this tool while conducting user testing. Encourage them to try it out!

**Guidelines for the working session:**

1. Students should begin filling out the Usability Testing Challenge Template for conducting user tests.
2. Students can continue user testing from the activity earlier in class.
3. Students can get feedback on their previous work.

> **Instructor Note:** Invite questions before moving on to your recap of the lesson. 

## 12. Instructor Do: Recap and End Class (3 min)

**First things first:** Remind students that next class will be a working session where students will present their prototypes and work to wrap up their case study challenge.

Next, use this time to review the key concepts from the lesson, which helps to move what students learned
from their working memory into their long-term memory.

> :globe_with_meridians: **Online Recommendation:** Students can raise their hands and answer aloud or use Slack to post their answers.

- What is the purpose of a usability testing plan?
  - *Answer: To prepare to validate if your prototype and solution works for your user.*
- What's in a usability testing plan?
  - *Answer: 
    - A moderator guide
    - Definitions of user goals
    - A specific and measurable scenario to test
    - The tasks and steps for a scenario
    - A plan to report the usability testing results
- What did you learn about analyzing testing data?
  - *Answer: It is not as hard as it looks, and the value it creates is essential to the design process.*
- What is the value of UX metrics?
  - *Answer: UX metrics are a set of quantitative data points used to measure, compare, and track the user experience of a website or app over time.

> **Instructor Note:** Take questions.
>
> - If there are too many questions, encourage students to stay online for office hours. 

> :gem: **Designer Insight:** Consider enticing students to stay online for office hours by promising to share a great anecdote from the real world of design! 

- Thank everyone for doing their best work. 

- Stay online for office hours.

## 13. Instructor Do: Office Hours - Weekly Challenge Questions (30 min)

> :pushpin: **Important Point:** The goal for office hours is to set aside time after class to take challenge questions and conduct a challenge critique.


Some suggestions:

- Allow the students to ask questions.

> **Instructor Note:** Students will often misread the challenge instructions or try to jump ahead. Ask them if they started at the beginning.

- Encourage students to make progress. It's hard to provide critique when there isn't work to review.

- Ask students to present their work for feedback. 

---

## We Want Your Feedback!

Please submit any issues or comments on the UX/UI curriculum to our Google Form: [Submit Issues](https://docs.google.com/forms/d/e/1FAIpQLScTc104D7Fd-2fDk3E4IIwxuOe-BNhPhWffIE9VBt7_e-t3DA/viewform).

With this form, you can now view the status of your submission and other issues here: [Issue Status](https://docs.google.com/spreadsheets/d/1UyRh0f6fwtMD5SfExvk3BZxIIioicTNhXWixjmnes1c/edit?usp=sharing).

---

## Copyright

© 2022 edX Boot Camps LLC. Confidential and Proprietary. All Rights Reserved.
